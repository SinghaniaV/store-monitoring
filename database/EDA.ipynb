{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy.engine.base import Engine\n",
    "from sqlalchemy import create_engine\n",
    "from schema import Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vishal/Codebase/VSCodeProjects/loopai-fastApiProject/database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2515297/2822089566.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  time_zone_df['timezone_str'].fillna('America/Chicago', inplace=True)\n",
      "/tmp/ipykernel_2515297/2822089566.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  status_df['timezone_str'].fillna('America/Chicago', inplace=True)\n",
      "/tmp/ipykernel_2515297/2822089566.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  business_hours_df['timezone_str'].fillna('America/Chicago', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "# reading csv files\n",
    "status_df: pd.DataFrame = read_data(cwd+'/data/store_status.csv')\n",
    "time_zone_df: pd.DataFrame = read_data(cwd+'/data/time_zones.csv')\n",
    "business_hours_df: pd.DataFrame = read_data(cwd+'/data/menu_hours.csv')\n",
    "\n",
    "# Ensure timestamp_utc is in datetime format\n",
    "status_df['timestamp_utc'] = pd.to_datetime(status_df['timestamp_utc'], format='mixed')\n",
    "\n",
    "# Fill missing timezones with 'America/Chicago'\n",
    "time_zone_df['timezone_str'].fillna('America/Chicago', inplace=True)\n",
    "\n",
    "# Merge status_df with time_zone_df on store_id\n",
    "status_df = status_df.merge(time_zone_df, on='store_id', how='left')\n",
    "\n",
    "# Fill missing timezone_str with 'America/Chicago'\n",
    "status_df['timezone_str'].fillna('America/Chicago', inplace=True)\n",
    "\n",
    "# Merge business_hours_df with time_zone_df on store_id\n",
    "business_hours_df = business_hours_df.merge(time_zone_df, on='store_id', how='left')\n",
    "\n",
    "# Fill missing timezone_str with 'America/Chicago'\n",
    "business_hours_df['timezone_str'].fillna('America/Chicago', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_utc(local_time_str, dayOfWeek, tz_str):\n",
    "    local_tz = pytz.timezone(tz_str)\n",
    "    # Create a datetime object for the start of the week\n",
    "    base_time = datetime.strptime('2024-08-05', '%Y-%m-%d') + timedelta(days=dayOfWeek)\n",
    "    # Add the local time to the base_time\n",
    "    local_time = datetime.strptime(local_time_str, '%H:%M:%S').replace(\n",
    "        year=base_time.year, month=base_time.month, day=base_time.day\n",
    "    )\n",
    "    local_time = local_tz.localize(local_time)\n",
    "    return local_time.astimezone(pytz.utc)\n",
    "\n",
    "# Convert start_time_local and end_time_local to UTC\n",
    "business_hours_df['start_time_utc'] = business_hours_df.apply(\n",
    "    lambda row: convert_to_utc(row['start_time_local'], row['day'], row['timezone_str']), axis=1\n",
    ")\n",
    "\n",
    "business_hours_df['end_time_utc'] = business_hours_df.apply(\n",
    "    lambda row: convert_to_utc(row['end_time_local'], row['day'], row['timezone_str']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 75\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Calculate uptime and downtime\u001b[39;00m\n\u001b[1;32m     74\u001b[0m now \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp\u001b[38;5;241m.\u001b[39mutcnow()\n\u001b[0;32m---> 75\u001b[0m report_df \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_uptime_downtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbusiness_hours_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# inserting data into the database.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[16], line 39\u001b[0m, in \u001b[0;36mcalculate_uptime_downtime\u001b[0;34m(status_df, business_hours_df, now)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_business_hours:\n\u001b[0;32m---> 39\u001b[0m     status_row \u001b[38;5;241m=\u001b[39m \u001b[43mstore_status\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_status\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp_utc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcurrent_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp_utc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     42\u001b[0m     status \u001b[38;5;241m=\u001b[39m status_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m status_row\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minactive\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactive\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/Codebase/VSCodeProjects/loopai-fastApiProject/.venv/lib/python3.12/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Codebase/VSCodeProjects/loopai-fastApiProject/.venv/lib/python3.12/site-packages/pandas/core/indexing.py:1754\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m-> 1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Codebase/VSCodeProjects/loopai-fastApiProject/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4001\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3999\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_mgr\u001b[38;5;241m.\u001b[39marray, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4000\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced_from_mgr(new_mgr, axes\u001b[38;5;241m=\u001b[39mnew_mgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m-> 4001\u001b[0m result\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   4002\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   4003\u001b[0m result\u001b[38;5;241m.\u001b[39m_set_is_copy(\u001b[38;5;28mself\u001b[39m, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/Codebase/VSCodeProjects/loopai-fastApiProject/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:5388\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5384\u001b[0m getitem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m\n\u001b[1;32m   5386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mor\u001b[39;00m is_float(key):\n\u001b[1;32m   5387\u001b[0m     \u001b[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[0;32m-> 5388\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast_scalar_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m getitem(key)\n\u001b[1;32m   5391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   5392\u001b[0m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[1;32m   5393\u001b[0m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n",
      "File \u001b[0;32m~/Codebase/VSCodeProjects/loopai-fastApiProject/.venv/lib/python3.12/site-packages/pandas/core/common.py:165\u001b[0m, in \u001b[0;36mcast_scalar_indexer\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03mDisallow indexing with a float key, even if that key is a round number.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03moutval : scalar\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# assumes lib.is_scalar(val)\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mis_integer():\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;66;03m# GH#34193\u001b[39;00m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing with a float is no longer supported. Manually convert \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto an integer key instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def calculate_uptime_downtime(status_df, business_hours_df, now):\n",
    "    results = []\n",
    "\n",
    "    for store_id in status_df['store_id'].unique():\n",
    "        store_status = status_df[status_df['store_id'] == store_id]\n",
    "        store_hours = business_hours_df[business_hours_df['store_id'] == store_id]\n",
    "        \n",
    "        # Assume 24/7 if no business hours data\n",
    "        if store_hours.empty:\n",
    "            store_hours = pd.DataFrame([{\n",
    "                'store_id': store_id, 'day': day, 'start_time_utc': now - timedelta(days=7),\n",
    "                'end_time_utc': now + timedelta(days=7), 'timezone_str': 'America/Chicago'\n",
    "            } for day in range(7)])\n",
    "        \n",
    "        # Initialize uptime and downtime counters\n",
    "        uptime_last_hour = downtime_last_hour = 0\n",
    "        uptime_last_day = downtime_last_day = 0\n",
    "        uptime_last_week = downtime_last_week = 0\n",
    "        \n",
    "        intervals = [\n",
    "            ('last_hour', now - timedelta(hours=1)),\n",
    "            ('last_day', now - timedelta(days=1)),\n",
    "            ('last_week', now - timedelta(weeks=1))\n",
    "        ]\n",
    "        \n",
    "        for interval_name, interval_start in intervals:\n",
    "            uptime = 0\n",
    "            downtime = 0\n",
    "            current_time = interval_start\n",
    "            \n",
    "            while current_time < now:\n",
    "                is_business_hours = False\n",
    "                for _, hours_row in store_hours.iterrows():\n",
    "                    if hours_row['start_time_utc'] <= current_time < hours_row['end_time_utc']:\n",
    "                        is_business_hours = True\n",
    "                        break\n",
    "                \n",
    "                if is_business_hours:\n",
    "                    status_row = store_status[\n",
    "                        (store_status['timestamp_utc'] <= current_time)\n",
    "                    ].sort_values(by='timestamp_utc').iloc[-1]\n",
    "                    status = status_row['status'] if not status_row.empty else 'inactive'\n",
    "                    if status == 'active':\n",
    "                        uptime += 1\n",
    "                    else:\n",
    "                        downtime += 1\n",
    "                \n",
    "                current_time += timedelta(minutes=1)\n",
    "            \n",
    "            if interval_name == 'last_hour':\n",
    "                uptime_last_hour = uptime\n",
    "                downtime_last_hour = downtime\n",
    "            elif interval_name == 'last_day':\n",
    "                uptime_last_day = uptime / 60\n",
    "                downtime_last_day = downtime / 60\n",
    "            elif interval_name == 'last_week':\n",
    "                uptime_last_week = uptime / 60\n",
    "                downtime_last_week = downtime / 60\n",
    "        \n",
    "        results.append({\n",
    "            'report_id': 'report1',\n",
    "            'store_id': store_id,\n",
    "            'uptime_last_hour': uptime_last_hour,\n",
    "            'downtime_last_hour': downtime_last_hour,\n",
    "            'uptime_last_day': uptime_last_day,\n",
    "            'downtime_last_day': downtime_last_day,\n",
    "            'uptime_last_week': uptime_last_week,\n",
    "            'downtime_last_week': downtime_last_week\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Calculate uptime and downtime\n",
    "now = pd.Timestamp.utcnow()\n",
    "report_df = calculate_uptime_downtime(status_df, business_hours_df, now)\n",
    "\n",
    "\n",
    "# inserting data into the database.\n",
    "start_time = time.time()\n",
    "try:\n",
    "    # connecting to SQLite.\n",
    "    engine = get_connection()\n",
    "    report_df.to_sql('reports', con=engine, chunksize=10000, if_exists='replace', index=False)\n",
    "except Exception as insert_exception:\n",
    "    print(f'Unable to populate tables, {repr(insert_exception)}')\n",
    "else:\n",
    "    end_time = time.time()\n",
    "    execution_time = (end_time - start_time) / 60\n",
    "    print(f'Successful in creating and populating the tables in {execution_time:.2f} minutes')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
